'use client';

import { useState, useEffect, useCallback, useRef } from 'react';
import { useLocalParticipant } from '@livekit/components-react';
import { Track, createLocalAudioTrack, LocalAudioTrack } from 'livekit-client';
import { AudioProcessingSettings, VADPresetConfig } from '../types/audio';

// å¯¼å‡º AudioProcessingSettings ç±»å‹
export type { AudioProcessingSettings } from '../types/audio';

export interface AudioProcessingControls {
    settings: AudioProcessingSettings;
    updateSetting: (key: keyof AudioProcessingSettings, value: boolean | number | string) => Promise<void>;
    updateMultipleSettings: (updates: Partial<AudioProcessingSettings>) => Promise<void>;
    isApplying: (key: keyof AudioProcessingSettings) => boolean;
    resetToDefaults: () => Promise<void>;
    applyPreset: (preset: VADPresetConfig) => Promise<void>;
    getPresets: () => VADPresetConfig[];
    applyingSettings: Set<string>; // æ·»åŠ è¿™ä¸ªå¯¼å‡º
}

// VADé¢„è®¾é…ç½®
const VAD_PRESETS: VADPresetConfig[] = [
    {
        name: 'quiet',
        description: 'å®‰é™ç¯å¢ƒ - é«˜æ•æ„Ÿåº¦',
        settings: {
            threshold: 0.1,
            smoothingFactor: 0.9,
            minSpeechFrames: 2,
            minSilenceFrames: 15,
            analyzeWindow: 20
        }
    },
    {
        name: 'normal',
        description: 'æ­£å¸¸ç¯å¢ƒ - å¹³è¡¡è®¾ç½®',
        settings: {
            threshold: 0.3,
            smoothingFactor: 0.8,
            minSpeechFrames: 3,
            minSilenceFrames: 10,
            analyzeWindow: 30
        }
    },
    {
        name: 'noisy',
        description: 'å˜ˆæ‚ç¯å¢ƒ - ä½æ•æ„Ÿåº¦',
        settings: {
            threshold: 0.5,
            smoothingFactor: 0.7,
            minSpeechFrames: 5,
            minSilenceFrames: 8,
            analyzeWindow: 40
        }
    },
    {
        name: 'conference',
        description: 'ä¼šè®®æ¨¡å¼ - ä¼˜åŒ–å¤šäººå¯¹è¯',
        settings: {
            threshold: 0.25,
            smoothingFactor: 0.85,
            minSpeechFrames: 2,
            minSilenceFrames: 12,
            analyzeWindow: 25
        }
    }
];

const DEFAULT_SETTINGS: AudioProcessingSettings = {
    autoGainControl: true,
    noiseSuppression: true,
    echoCancellation: false,
    microphoneThreshold: 0.3,
    
    // VADè®¾ç½®
    vadEnabled: false,
    vadThreshold: 0.3,
    vadSmoothingFactor: 0.8,
    vadMinSpeechFrames: 3,
    vadMinSilenceFrames: 10,
    vadAnalyzeWindow: 30,
    
    // é«˜çº§VADè®¾ç½® - ä¿®å¤é»˜è®¤å€¼ç±»å‹
    vadSensitivity: 'medium' as const, // ä½¿ç”¨ 'medium' è€Œä¸æ˜¯ 'normal'
    vadNoiseGate: true,
    vadHoldTime: 100,
    vadAttackTime: 50,
    vadReleaseTime: 200
};

// æœ¬åœ°å­˜å‚¨é”®
const STORAGE_KEY = 'livekit_audio_processing_settings';

export function useAudioProcessing(): AudioProcessingControls {
    const { localParticipant } = useLocalParticipant();
    
    // ä»æœ¬åœ°å­˜å‚¨åŠ è½½è®¾ç½®
    const loadSettings = useCallback((): AudioProcessingSettings => {
        if (typeof window === 'undefined') return DEFAULT_SETTINGS;
        
        try {
            const stored = localStorage.getItem(STORAGE_KEY);
            if (stored) {
                const parsed = JSON.parse(stored);
                return { ...DEFAULT_SETTINGS, ...parsed };
            }
        } catch (error) {
            console.warn('åŠ è½½éŸ³é¢‘å¤„ç†è®¾ç½®å¤±è´¥:', error);
        }
        return DEFAULT_SETTINGS;
    }, []);

    const [settings, setSettings] = useState<AudioProcessingSettings>(loadSettings);
    const [applyingSettings, setApplyingSettings] = useState<Set<string>>(new Set());
    const currentTrackRef = useRef<LocalAudioTrack | null>(null);
    const initializedRef = useRef(false);

    // ä¿å­˜è®¾ç½®åˆ°æœ¬åœ°å­˜å‚¨
    const saveSettings = useCallback((newSettings: AudioProcessingSettings) => {
        if (typeof window !== 'undefined') {
            try {
                localStorage.setItem(STORAGE_KEY, JSON.stringify(newSettings));
            } catch (error) {
                console.warn('ä¿å­˜éŸ³é¢‘å¤„ç†è®¾ç½®å¤±è´¥:', error);
            }
        }
    }, []);

    // æ£€æµ‹å½“å‰è½¨é“çš„å®é™…éŸ³é¢‘è®¾ç½®
    const getCurrentTrackSettings = useCallback((): MediaTrackSettings | null => {
        if (!localParticipant) return null;
        
        const audioPublication = localParticipant.getTrackPublication(Track.Source.Microphone);
        if (audioPublication?.track) {
            return audioPublication.track.mediaStreamTrack.getSettings();
        }
        return null;
    }, [localParticipant]);

    // åŒæ­¥æ˜¾ç¤ºè®¾ç½®ä¸å®é™…è®¾ç½®
    const syncSettingsWithActualTrack = useCallback(() => {
        const actualSettings = getCurrentTrackSettings();
        if (actualSettings && !initializedRef.current) {
            console.log('ğŸ” æ£€æµ‹åˆ°å®é™…éŸ³é¢‘è®¾ç½®:', actualSettings);
            
            const syncedSettings: AudioProcessingSettings = {
                ...settings,
                echoCancellation: actualSettings.echoCancellation ?? false,
                noiseSuppression: actualSettings.noiseSuppression ?? true,
                autoGainControl: actualSettings.autoGainControl ?? true,
            };

            const hasChanges = 
                syncedSettings.echoCancellation !== settings.echoCancellation ||
                syncedSettings.noiseSuppression !== settings.noiseSuppression ||
                syncedSettings.autoGainControl !== settings.autoGainControl;

            if (hasChanges) {
                console.log('ğŸ”„ åŒæ­¥éŸ³é¢‘è®¾ç½®:', {
                    previous: settings,
                    actual: actualSettings,
                    synced: syncedSettings
                });
                
                setSettings(syncedSettings);
                saveSettings(syncedSettings);
            }
            
            initializedRef.current = true;
        }
    }, [settings, getCurrentTrackSettings, saveSettings]);

    // åº”ç”¨éŸ³é¢‘çº¦æŸåˆ°è½¨é“
    const applyAudioConstraints = useCallback(async (newSettings: AudioProcessingSettings) => {
        if (!localParticipant) {
            console.warn('æœ¬åœ°å‚ä¸è€…ä¸å­˜åœ¨ï¼Œæ— æ³•åº”ç”¨éŸ³é¢‘è®¾ç½®');
            return;
        }

        console.log('ğŸ›ï¸ å¼€å§‹åº”ç”¨éŸ³é¢‘å¤„ç†è®¾ç½®:', newSettings);

        try {
            const audioPublication = localParticipant.getTrackPublication(Track.Source.Microphone);
            const wasEnabled = audioPublication ? !audioPublication.isMuted : false;

            console.log(`ğŸ¤ å½“å‰éº¦å…‹é£çŠ¶æ€: ${wasEnabled ? 'å¯ç”¨' : 'ç¦ç”¨'}`);

            if (audioPublication?.track) {
                console.log('ğŸ›‘ åœæ­¢å½“å‰éŸ³é¢‘è½¨é“');
                audioPublication.track.stop();
                await localParticipant.unpublishTrack(audioPublication.track);
                console.log('ğŸ“¤ å·²å–æ¶ˆå‘å¸ƒå½“å‰éŸ³é¢‘è½¨é“');
                
                if (currentTrackRef.current === audioPublication.track) {
                    currentTrackRef.current = null;
                }
            }

            await new Promise(resolve => setTimeout(resolve, 300));

            const audioConstraints: MediaTrackConstraints = {
                echoCancellation: newSettings.echoCancellation,
                noiseSuppression: newSettings.noiseSuppression,
                autoGainControl: newSettings.autoGainControl,
                sampleRate: { ideal: 48000 },
                channelCount: { ideal: 1 },
            };

            console.log('ğŸ›ï¸ åº”ç”¨éŸ³é¢‘çº¦æŸ:', audioConstraints);

            const newAudioTrack = await createLocalAudioTrack({
                ...audioConstraints,
                deviceId: 'default'
            });

            console.log('âœ… æ–°éŸ³é¢‘è½¨é“å·²åˆ›å»º');

            const appliedSettings = newAudioTrack.mediaStreamTrack.getSettings();
            console.log('ğŸ” éªŒè¯æ–°è½¨é“è®¾ç½®:', {
                requested: audioConstraints,
                applied: appliedSettings
            });

            currentTrackRef.current = newAudioTrack;

            await localParticipant.publishTrack(newAudioTrack, {
                name: 'microphone',
                source: Track.Source.Microphone
            });

            console.log('ğŸ“¤ æ–°éŸ³é¢‘è½¨é“å·²å‘å¸ƒ');

            if (wasEnabled) {
                await localParticipant.setMicrophoneEnabled(true);
                console.log('ğŸ¤ éº¦å…‹é£å·²é‡æ–°å¯ç”¨');
            }

            setTimeout(() => {
                const finalPublication = localParticipant.getTrackPublication(Track.Source.Microphone);
                if (finalPublication?.track) {
                    const actualSettings = finalPublication.track.mediaStreamTrack.getSettings();
                    console.log('ğŸ” æœ€ç»ˆéªŒè¯éŸ³é¢‘è®¾ç½®:', {
                        applied: actualSettings,
                        expected: newSettings,
                        microphoneEnabled: localParticipant.isMicrophoneEnabled
                    });

                    const mismatch = {
                        echoCancellation: actualSettings.echoCancellation !== newSettings.echoCancellation,
                        noiseSuppression: actualSettings.noiseSuppression !== newSettings.noiseSuppression,
                        autoGainControl: actualSettings.autoGainControl !== newSettings.autoGainControl
                    };

                    if (mismatch.echoCancellation || mismatch.noiseSuppression || mismatch.autoGainControl) {
                        console.warn('âš ï¸ æ£€æµ‹åˆ°è®¾ç½®ä¸åŒ¹é…:', mismatch);
                    }
                }
            }, 1000);

        } catch (error) {
            console.error('âŒ åº”ç”¨éŸ³é¢‘å¤„ç†è®¾ç½®å¤±è´¥:', error);
            
            try {
                console.log('ğŸ”„ å°è¯•æ¢å¤åŸºç¡€éŸ³é¢‘åŠŸèƒ½...');
                await localParticipant.setMicrophoneEnabled(true);
                console.log('âœ… åŸºç¡€éŸ³é¢‘åŠŸèƒ½å·²æ¢å¤');
            } catch (recoveryError) {
                console.error('âŒ éŸ³é¢‘æ¢å¤å¤±è´¥:', recoveryError);
            }
            
            throw error;
        }
    }, [localParticipant]);

    // æ›´æ–°å•ä¸ªè®¾ç½®
    const updateSetting = useCallback(async (
        key: keyof AudioProcessingSettings, 
        value: boolean | number | string
    ) => {
        const settingKey = String(key); // è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        
        if (applyingSettings.has(settingKey)) {
            console.log(`â³ ${key} è®¾ç½®æ­£åœ¨åº”ç”¨ä¸­ï¼Œè·³è¿‡`);
            return;
        }

        setApplyingSettings(prev => new Set(prev).add(settingKey));

        try {
            const newSettings = { ...settings, [key]: value };
            
            setSettings(newSettings);
            saveSettings(newSettings);

            // å¯¹äºéŸ³é¢‘å¤„ç†ç›¸å…³è®¾ç½®ï¼Œéœ€è¦é‡æ–°åˆ›å»ºè½¨é“
            if (key === 'autoGainControl' || key === 'noiseSuppression' || key === 'echoCancellation') {
                console.log(`ğŸ”„ å¼€å§‹åº”ç”¨ ${key} è®¾ç½®: ${value}`);
                await applyAudioConstraints(newSettings);
                console.log(`âœ… ${key} è®¾ç½®å·²åº”ç”¨: ${value}`);
            } else {
                // VADå’Œå…¶ä»–è®¾ç½®ä¸éœ€è¦é‡æ–°åˆ›å»ºè½¨é“
                console.log(`âœ… ${key} è®¾ç½®å·²æ›´æ–°: ${value}`);
            }

        } catch (error) {
            console.error(`âŒ æ›´æ–° ${key} è®¾ç½®å¤±è´¥:`, error);
            setSettings(settings);
            throw error;
        } finally {
            setApplyingSettings(prev => {
                const newSet = new Set(prev);
                newSet.delete(settingKey);
                return newSet;
            });
        }
    }, [settings, applyingSettings, saveSettings, applyAudioConstraints]);

    // æ‰¹é‡æ›´æ–°è®¾ç½®
    const updateMultipleSettings = useCallback(async (updates: Partial<AudioProcessingSettings>) => {
        const settingKeys = Object.keys(updates) as (keyof AudioProcessingSettings)[];
        const applyingKey = 'batch_update';
        
        if (applyingSettings.has(applyingKey)) {
            console.log('â³ æ‰¹é‡æ›´æ–°æ­£åœ¨è¿›è¡Œä¸­ï¼Œè·³è¿‡');
            return;
        }

        setApplyingSettings(prev => new Set(prev).add(applyingKey));

        try {
            const newSettings = { ...settings, ...updates };
            
            setSettings(newSettings);
            saveSettings(newSettings);

            // æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°åˆ›å»ºè½¨é“
            const needsTrackRecreation = settingKeys.some(key => 
                key === 'autoGainControl' || key === 'noiseSuppression' || key === 'echoCancellation'
            );

            if (needsTrackRecreation) {
                console.log('ğŸ”„ æ‰¹é‡åº”ç”¨éŸ³é¢‘å¤„ç†è®¾ç½®');
                await applyAudioConstraints(newSettings);
                console.log('âœ… æ‰¹é‡è®¾ç½®å·²åº”ç”¨');
            } else {
                console.log('âœ… æ‰¹é‡è®¾ç½®å·²æ›´æ–°ï¼ˆæ— éœ€é‡æ–°åˆ›å»ºè½¨é“ï¼‰');
            }

        } catch (error) {
            console.error('âŒ æ‰¹é‡æ›´æ–°è®¾ç½®å¤±è´¥:', error);
            setSettings(settings);
            throw error;
        } finally {
            setApplyingSettings(prev => {
                const newSet = new Set(prev);
                newSet.delete(applyingKey);
                return newSet;
            });
        }
    }, [settings, applyingSettings, saveSettings, applyAudioConstraints]);

    // æ£€æŸ¥æ˜¯å¦æ­£åœ¨åº”ç”¨è®¾ç½®
    const isApplying = useCallback((key: keyof AudioProcessingSettings) => {
        return applyingSettings.has(String(key)) || applyingSettings.has('batch_update');
    }, [applyingSettings]);

    // é‡ç½®ä¸ºé»˜è®¤è®¾ç½®
    const resetToDefaults = useCallback(async () => {
        console.log('ğŸ”„ é‡ç½®éŸ³é¢‘å¤„ç†è®¾ç½®ä¸ºé»˜è®¤å€¼');
        
        try {
            setSettings(DEFAULT_SETTINGS);
            saveSettings(DEFAULT_SETTINGS);
            await applyAudioConstraints(DEFAULT_SETTINGS);
            console.log('âœ… å·²é‡ç½®ä¸ºé»˜è®¤è®¾ç½®');
            initializedRef.current = false;
        } catch (error) {
            console.error('âŒ é‡ç½®è®¾ç½®å¤±è´¥:', error);
            throw error;
        }
    }, [saveSettings, applyAudioConstraints]);

    // åº”ç”¨VADé¢„è®¾
    const applyPreset = useCallback(async (preset: VADPresetConfig) => {
        console.log(`ğŸ›ï¸ åº”ç”¨VADé¢„è®¾: ${preset.name}`);
        
        try {
            await updateMultipleSettings({
                vadThreshold: preset.settings.threshold,
                vadSmoothingFactor: preset.settings.smoothingFactor,
                vadMinSpeechFrames: preset.settings.minSpeechFrames,
                vadMinSilenceFrames: preset.settings.minSilenceFrames,
                vadAnalyzeWindow: preset.settings.analyzeWindow,
                vadSensitivity: 'custom'
            });
            console.log(`âœ… VADé¢„è®¾ ${preset.name} å·²åº”ç”¨`);
        } catch (error) {
            console.error(`âŒ åº”ç”¨VADé¢„è®¾ ${preset.name} å¤±è´¥:`, error);
            throw error;
        }
    }, [updateMultipleSettings]);

    // è·å–é¢„è®¾åˆ—è¡¨
    const getPresets = useCallback(() => VAD_PRESETS, []);

    // ç»„ä»¶æŒ‚è½½æ—¶åˆå§‹åŒ–
    useEffect(() => {
        if (localParticipant && !initializedRef.current) {
            console.log('ğŸ¤ åˆå§‹åŒ–éŸ³é¢‘å¤„ç†æ¨¡å—');
            
            const audioPublication = localParticipant.getTrackPublication(Track.Source.Microphone);
            if (audioPublication?.track) {
                currentTrackRef.current = audioPublication.track as LocalAudioTrack;
                setTimeout(() => syncSettingsWithActualTrack(), 1000);
            }
        }
    }, [localParticipant, syncSettingsWithActualTrack]);

    // ç›‘å¬è½¨é“å˜åŒ–
    useEffect(() => {
        if (localParticipant) {
            const handleTrackSubscribed = () => {
                setTimeout(() => syncSettingsWithActualTrack(), 500);
            };

            localParticipant.on('trackPublished', handleTrackSubscribed);
            
            return () => {
                localParticipant.off('trackPublished', handleTrackSubscribed);
            };
        }
    }, [localParticipant, syncSettingsWithActualTrack]);

    // æ¸…ç†å‡½æ•°
    useEffect(() => {
        return () => {
            console.log('ğŸ§¹ æ¸…ç†éŸ³é¢‘å¤„ç†æ¨¡å—');
            if (currentTrackRef.current) {
                currentTrackRef.current = null;
            }
            initializedRef.current = false;
        };
    }, []);

    return {
        settings,
        updateSetting,
        updateMultipleSettings,
        isApplying,
        resetToDefaults,
        applyPreset,
        getPresets,
        applyingSettings // å¯¼å‡ºè¿™ä¸ªå±æ€§
    };
}