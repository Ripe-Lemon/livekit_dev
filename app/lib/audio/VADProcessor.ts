'use client';

export interface VADResult {
    probability: number; // 0-1 èŒƒå›´ï¼Œè¯­éŸ³æ£€æµ‹æ¦‚ç‡
    isSpeaking: boolean; // æ˜¯å¦æ­£åœ¨è¯´è¯
    volume: number; // éŸ³é‡çº§åˆ« 0-1
}

export interface VADConfig {
    threshold: number; // è¯­éŸ³æ£€æµ‹é˜ˆå€¼ 0-1
    smoothingFactor: number; // å¹³æ»‘å› å­ 0-1
    minSpeechFrames: number; // æœ€å°è¯­éŸ³å¸§æ•°
    minSilenceFrames: number; // æœ€å°é™éŸ³å¸§æ•°
    analyzeWindow: number; // åˆ†æçª—å£å¤§å°(æ¯«ç§’)
}

const DEFAULT_VAD_CONFIG: VADConfig = {
    threshold: 0.3,
    smoothingFactor: 0.8,
    minSpeechFrames: 3,
    minSilenceFrames: 10,
    analyzeWindow: 30 // 30ms
};

export class VADProcessor {
    private audioContext: AudioContext | null = null;
    private analyserNode: AnalyserNode | null = null;
    private microphoneSource: MediaStreamAudioSourceNode | null = null;
    private isActive = false;
    private config: VADConfig;
    private dataArray: Uint8Array | null = null;
    private freqDataArray: Uint8Array | null = null;
    private audioGateway: VADAudioGateway | null = null;
    private onSpeechStateChange: ((isSpeaking: boolean) => void) | null = null;
    
    // VAD çŠ¶æ€
    private currentVolume = 0;
    private smoothedVolume = 0;
    private speechFrameCount = 0;
    private silenceFrameCount = 0;
    private isSpeaking = false;
    private lastAnalysisTime = 0;
    
    // é¢‘è°±åˆ†æç›¸å…³
    private speechFreqBands = {
        low: { min: 85, max: 255 },      // 85-255 Hz (åŸºé¢‘)
        mid: { min: 255, max: 2000 },    // 255-2000 Hz (ä¸»è¦è¯­éŸ³é¢‘æ®µ)
        high: { min: 2000, max: 4000 }   // 2000-4000 Hz (è¯­éŸ³æ¸…æ™°åº¦)
    };

    // å†å²æ•°æ®ç”¨äºæ›´æ™ºèƒ½çš„æ£€æµ‹
    private volumeHistory: number[] = [];
    private readonly historySize = 10;

    // å›è°ƒå‡½æ•°
    private onVADUpdate: ((result: VADResult) => void) | null = null;

    // æ·»åŠ è°ƒè¯•çŠ¶æ€
    private debugMode = process.env.NODE_ENV === 'development';
    private analysisCount = 0;
    private lastVolumeUpdate = 0;

    constructor(config: Partial<VADConfig> = {}) {
        this.config = { ...DEFAULT_VAD_CONFIG, ...config };
        this.initializeAudioContext();
    }

    private startAnalysis() {
        if (this.isActive) return;
        
        this.isActive = true;
        console.log('ğŸ” VAD åˆ†æå·²å¼€å§‹');
        
        const analyze = () => {
            if (!this.isActive || !this.analyserNode || !this.dataArray || !this.freqDataArray) {
                return;
            }

            const now = Date.now();
            if (now - this.lastAnalysisTime < this.config.analyzeWindow) {
                requestAnimationFrame(analyze);
                return;
            }
            this.lastAnalysisTime = now;

            try {
                // è·å–éŸ³é¢‘æ•°æ®
                this.analyserNode.getByteTimeDomainData(this.dataArray);
                this.analyserNode.getByteFrequencyData(this.freqDataArray);

                // éªŒè¯æ•°æ®æœ‰æ•ˆæ€§
                const hasData = this.dataArray.some(value => value !== 128) || 
                               this.freqDataArray.some(value => value > 0);

                if (!hasData) {
                    if (this.debugMode && this.analysisCount % 100 === 0) {
                        console.warn('âš ï¸ VADæœªæ£€æµ‹åˆ°éŸ³é¢‘æ•°æ®ï¼Œæ£€æŸ¥éº¦å…‹é£è¿æ¥');
                    }
                } else {
                    // åˆ†æéŸ³é¢‘
                    const result = this.analyzeAudio();
                    
                    // è§¦å‘å›è°ƒ
                    if (this.onVADUpdate) {
                        this.onVADUpdate(result);
                    }

                    // è°ƒè¯•è¾“å‡ºï¼ˆé™ä½é¢‘ç‡ï¼‰
                    if (this.debugMode && this.analysisCount % 50 === 0) {
                        console.log('ğŸ” VADæ•°æ®é‡‡æ ·:', {
                            analysisCount: this.analysisCount,
                            volume: result.volume.toFixed(3),
                            probability: result.probability.toFixed(3),
                            isSpeaking: result.isSpeaking,
                            dataArraySample: Array.from(this.dataArray.slice(0, 10)),
                            freqArraySample: Array.from(this.freqDataArray.slice(0, 10)),
                            audioContextState: this.audioContext?.state
                        });
                    }
                }

                this.analysisCount++;
            } catch (error) {
                console.error('âŒ VADåˆ†æé”™è¯¯:', error);
            }

            requestAnimationFrame(analyze);
        };

        requestAnimationFrame(analyze);
    }

    private analyzeAudio(): VADResult {
        if (!this.dataArray || !this.freqDataArray) {
            return { probability: 0, isSpeaking: false, volume: 0 };
        }

        // 1. è®¡ç®—éŸ³é‡ (RMS)
        const volume = this.calculateVolume();
        this.currentVolume = volume;

        // 2. ä¿®å¤å¹³æ»‘éŸ³é‡ç®—æ³• - æé«˜å“åº”æ€§
        // å½“éŸ³é‡ä¸Šå‡æ—¶ä½¿ç”¨è¾ƒå°‘çš„å¹³æ»‘ï¼Œä¸‹é™æ—¶ä½¿ç”¨æ›´å¤šå¹³æ»‘
        const smoothingFactor = volume > this.smoothedVolume ? 
            this.config.smoothingFactor * 0.3 :  // ä¸Šå‡æ—¶å¿«é€Ÿå“åº”
            this.config.smoothingFactor;         // ä¸‹é™æ—¶æ­£å¸¸å¹³æ»‘
            
        this.smoothedVolume = this.smoothedVolume * smoothingFactor + 
                             volume * (1 - smoothingFactor);

        // 3. é¢‘è°±åˆ†æ
        const spectralFeatures = this.analyzeSpectrum();

        // 4. ä½¿ç”¨æ˜¾ç¤ºçš„éŸ³é‡å€¼ï¼ˆsmoothedVolumeï¼‰ç›´æ¥ä¸é˜ˆå€¼æ¯”è¾ƒ
        const volumeBasedProbability = this.smoothedVolume >= this.config.threshold ? 1.0 : 0.0;
        
        // 5. é¢‘è°±å¢å¼ºï¼ˆå¯é€‰ï¼Œå¢åŠ å‡†ç¡®æ€§ï¼‰
        const spectralBonus = this.calculateSpectralBonus(spectralFeatures);
        
        // 6. æœ€ç»ˆæ¦‚ç‡ï¼šä¸»è¦åŸºäºéŸ³é‡é˜ˆå€¼ï¼Œé¢‘è°±ä½œä¸ºè¾…åŠ©
        const probability = Math.min(volumeBasedProbability + spectralBonus * 0.2, 1.0);

        // 7. çŠ¶æ€æœºé€»è¾‘ - ä½¿ç”¨ä¸¥æ ¼çš„é˜ˆå€¼åˆ¤æ–­
        this.updateSpeechState(probability);

        // 8. æ›´æ–°å†å²æ•°æ®
        this.updateHistory(volume);

        // 9. è°ƒè¯•æ—¥å¿— - å¢åŠ æ›´è¯¦ç»†çš„éŸ³é‡ä¿¡æ¯
        const now = Date.now();
        if (this.debugMode && volume > 0.01 && now - this.lastVolumeUpdate > 1000) {
            console.log('ğŸ” VAD éŸ³é‡åˆ†æ:', {
                rawVolume: volume.toFixed(4),
                smoothedVolume: this.smoothedVolume.toFixed(4),
                threshold: this.config.threshold.toFixed(3),
                volumeExceedsThreshold: this.smoothedVolume >= this.config.threshold,
                probability: probability.toFixed(3),
                isSpeaking: this.isSpeaking,
                spectralBonus: spectralBonus.toFixed(3),
                // æ–°å¢ï¼šåŸå§‹æ•°æ®æ£€æŸ¥
                dataArrayMax: Math.max(...Array.from(this.dataArray)),
                dataArrayMin: Math.min(...Array.from(this.dataArray)),
                dataArrayAvg: Array.from(this.dataArray).reduce((a, b) => a + b, 0) / this.dataArray.length
            });
            this.lastVolumeUpdate = now;
        }

        return {
            probability,
            isSpeaking: this.isSpeaking,
            volume: this.smoothedVolume // ç¡®ä¿è¿”å›ä¸æ˜¾ç¤ºä¸€è‡´çš„éŸ³é‡å€¼
        };
    }

    // æ–°å¢ï¼šè®¡ç®—é¢‘è°±åŠ æˆ
    private calculateSpectralBonus(spectral: any): number {
        if (spectral.totalEnergy === 0) return 0;
        
        // è¯­éŸ³é¢‘æ®µèƒ½é‡æ¯”ä¾‹
        const speechRatio = spectral.speechEnergy / spectral.totalEnergy;
        
        // é¢‘è°±é‡å¿ƒåœ¨è¯­éŸ³èŒƒå›´å†…çš„åŠ æˆ
        const centroidBonus = spectral.spectralCentroid > 300 && spectral.spectralCentroid < 3000 ? 0.1 : 0;
        
        return Math.min(speechRatio * 0.3 + centroidBonus, 0.3); // æœ€å¤§30%åŠ æˆ
    }

    private calculateVolume(): number {
        if (!this.dataArray) return 0;

        let sum = 0;
        let max = 0;
        let nonZeroCount = 0;
        let varianceSum = 0;
        
        // é¦–å…ˆè®¡ç®—åŸºæœ¬ç»Ÿè®¡
        for (let i = 0; i < this.dataArray.length; i++) {
            const amplitude = Math.abs(this.dataArray[i] - 128) / 128;
            sum += amplitude * amplitude;
            max = Math.max(max, amplitude);
            if (this.dataArray[i] !== 128) nonZeroCount++;
        }
        
        // å¦‚æœæ‰€æœ‰æ•°æ®éƒ½æ˜¯128ï¼ˆé™éŸ³ï¼‰ï¼Œè¿”å›0
        if (nonZeroCount === 0) {
            return 0;
        }
        
        const rms = Math.sqrt(sum / this.dataArray.length);
        const mean = Math.sqrt(sum / this.dataArray.length);
        
        // è®¡ç®—æ–¹å·®æ¥æ£€æµ‹éŸ³é¢‘æ´»åŠ¨
        for (let i = 0; i < this.dataArray.length; i++) {
            const amplitude = Math.abs(this.dataArray[i] - 128) / 128;
            varianceSum += Math.pow(amplitude - mean, 2);
        }
        const variance = Math.sqrt(varianceSum / this.dataArray.length);
        
        // å¤šé‡å¢å¼ºç®—æ³•
        const rmsVolume = rms * 12;     // ä»8å€è¿›ä¸€æ­¥æé«˜åˆ°12å€
        const peakVolume = max * 3;     // å³°å€¼å¢å¼º
        const varianceVolume = variance * 8; // æ–¹å·®å¢å¼ºï¼Œæ£€æµ‹éŸ³é¢‘å˜åŒ–
        
        // ç»„åˆç®—æ³•ï¼šRMSä¸ºä¸»ï¼Œå³°å€¼å’Œæ–¹å·®ä¸ºè¾…
        const combinedVolume = (rmsVolume * 0.6) + (peakVolume * 0.2) + (varianceVolume * 0.2);
        
        // åº”ç”¨éçº¿æ€§å¢å¼ºæ›²çº¿
        const enhancedVolume = Math.pow(combinedVolume, 0.5); // ä½¿ç”¨å¹³æ–¹æ ¹å¢å¼ºå°ä¿¡å·
        
        // æ·»åŠ æœ€å°é˜ˆå€¼ï¼Œç¡®ä¿æœ‰éŸ³é¢‘è¾“å…¥æ—¶æœ‰å¯è§çš„éŸ³é‡
        const minThreshold = 0.02;
        const finalVolume = Math.max(
            enhancedVolume > minThreshold ? enhancedVolume : 0,
            0
        );
        
        // é™åˆ¶åœ¨0-1èŒƒå›´ï¼Œä½†å…è®¸è¾ƒé«˜çš„éŸ³é‡
        return Math.min(finalVolume, 1.0);
    }

    async connectToMicrophone(stream: MediaStream): Promise<void> {
        if (!this.audioContext) {
            await this.initializeAudioContext();
        }

        if (!this.audioContext) {
            throw new Error('éŸ³é¢‘ä¸Šä¸‹æ–‡åˆå§‹åŒ–å¤±è´¥');
        }

        try {
            console.log('ğŸ¤ VAD è¿æ¥åˆ°éº¦å…‹é£...');

            // åˆ›å»ºéŸ³é¢‘åˆ†æèŠ‚ç‚¹ - æœ€å¤§åŒ–æ•æ„Ÿåº¦è®¾ç½®
            this.analyserNode = this.audioContext.createAnalyser();
            this.analyserNode.fftSize = 4096;  // å¢åŠ åˆ°4096ä»¥è·å¾—æ›´å¥½çš„é¢‘ç‡åˆ†è¾¨ç‡
            this.analyserNode.smoothingTimeConstant = 0.1; // è¿›ä¸€æ­¥é™ä½åˆ°0.1ï¼Œæœ€å¤§åŒ–å“åº”é€Ÿåº¦
            this.analyserNode.minDecibels = -120; // è¿›ä¸€æ­¥é™ä½åˆ°-120ï¼Œæ•è·æå°çš„ä¿¡å·
            this.analyserNode.maxDecibels = -10;  // ä¿æŒä¸å˜

            // è¿æ¥éº¦å…‹é£è¾“å…¥
            this.microphoneSource = this.audioContext.createMediaStreamSource(stream);
            this.microphoneSource.connect(this.analyserNode);

            // åˆå§‹åŒ–æ•°æ®æ•°ç»„
            const bufferLength = this.analyserNode.frequencyBinCount;
            this.dataArray = new Uint8Array(bufferLength);
            this.freqDataArray = new Uint8Array(bufferLength);

            console.log('âœ… VAD å·²è¿æ¥åˆ°éº¦å…‹é£ï¼ˆé«˜æ•æ„Ÿåº¦é…ç½®ï¼‰', {
                fftSize: this.analyserNode.fftSize,
                bufferLength,
                sampleRate: this.audioContext.sampleRate,
                audioContextState: this.audioContext.state,
                minDecibels: this.analyserNode.minDecibels,
                maxDecibels: this.analyserNode.maxDecibels,
                smoothingTimeConstant: this.analyserNode.smoothingTimeConstant
            });

            // é‡ç½®è®¡æ•°å™¨
            this.analysisCount = 0;
            this.lastVolumeUpdate = Date.now();

            this.startAnalysis();
        } catch (error) {
            console.error('âŒ VAD è¿æ¥éº¦å…‹é£å¤±è´¥:', error);
            throw error;
        }
    }

    // ä¿®å¤åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿æ­£ç¡®æ¢å¤
    private async initializeAudioContext() {
        try {
            this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
            
            // ç¡®ä¿éŸ³é¢‘ä¸Šä¸‹æ–‡å¤„äºè¿è¡ŒçŠ¶æ€
            if (this.audioContext.state === 'suspended') {
                console.log('ğŸ¤ éŸ³é¢‘ä¸Šä¸‹æ–‡è¢«æš‚åœï¼Œæ­£åœ¨æ¢å¤...');
                await this.audioContext.resume();
                console.log('âœ… éŸ³é¢‘ä¸Šä¸‹æ–‡å·²æ¢å¤');
            }
            
            console.log('ğŸ¤ VAD AudioContext å·²åˆå§‹åŒ–', {
                state: this.audioContext.state,
                sampleRate: this.audioContext.sampleRate,
                destination: this.audioContext.destination
            });
        } catch (error) {
            console.error('âŒ VAD AudioContext åˆå§‹åŒ–å¤±è´¥:', error);
            throw error;
        }
    }

    // æ·»åŠ å®æ—¶éŸ³é‡ç›‘æ§æ–¹æ³•
    getRealTimeVolume(): number {
        if (!this.analyserNode || !this.dataArray) return 0;
        
        this.analyserNode.getByteTimeDomainData(this.dataArray);
        return this.calculateVolume();
    }

    // æ”¹è¿›æµ‹è¯•éŸ³é‡å“åº”æ–¹æ³•
    testVolumeResponse(): void {
        console.log('ğŸ§ª å¼€å§‹é«˜ç²¾åº¦éŸ³é‡å“åº”æµ‹è¯•...');
        
        if (!this.analyserNode || !this.dataArray) {
            console.error('âŒ åˆ†æå™¨æœªåˆå§‹åŒ–');
            return;
        }

        let testCount = 0;
        const maxTests = 60; // 60ç§’æµ‹è¯•
        
        const testInterval = setInterval(() => {
            this.analyserNode!.getByteTimeDomainData(this.dataArray!);
            
            // è®¡ç®—å¤šç§éŸ³é‡æŒ‡æ ‡
            let rms = 0;
            let peak = 0;
            let nonZeroCount = 0;
            let variance = 0;
            let totalAmplitude = 0;
            
            // è®¡ç®—åŸºç¡€ç»Ÿè®¡
            for (let i = 0; i < this.dataArray!.length; i++) {
                const amplitude = Math.abs(this.dataArray![i] - 128);
                totalAmplitude += amplitude;
                rms += amplitude * amplitude;
                peak = Math.max(peak, amplitude);
                if (this.dataArray![i] !== 128) nonZeroCount++;
            }
            
            const avgAmplitude = totalAmplitude / this.dataArray!.length;
            rms = Math.sqrt(rms / this.dataArray!.length);
            
            // è®¡ç®—æ–¹å·®
            for (let i = 0; i < this.dataArray!.length; i++) {
                const amplitude = Math.abs(this.dataArray![i] - 128);
                variance += Math.pow(amplitude - avgAmplitude, 2);
            }
            variance = Math.sqrt(variance / this.dataArray!.length);
            
            // å½’ä¸€åŒ–
            const rmsNormalized = rms / 128;
            const peakNormalized = peak / 128;
            const varianceNormalized = variance / 128;
            const dataPercent = (nonZeroCount / this.dataArray!.length) * 100;
            const ourAlgorithm = this.calculateVolume();
            
            if (rmsNormalized > 0.001 || ourAlgorithm > 0.001) {
                console.log(`ğŸ¤ éŸ³é‡æµ‹è¯• [${testCount + 1}/${maxTests}]:`, {
                    'æˆ‘ä»¬çš„ç®—æ³•': ourAlgorithm.toFixed(6),
                    'RMSæ ‡å‡†åŒ–': rmsNormalized.toFixed(6),
                    'å³°å€¼æ ‡å‡†åŒ–': peakNormalized.toFixed(6),
                    'æ–¹å·®æ ‡å‡†åŒ–': varianceNormalized.toFixed(6),
                    'æ•°æ®è¦†ç›–ç‡': `${dataPercent.toFixed(1)}%`,
                    'å¹³å‡æŒ¯å¹…': avgAmplitude.toFixed(2),
                    'éŸ³é¢‘ä¸Šä¸‹æ–‡': this.audioContext?.state,
                    'æ ·æœ¬æ•°æ®': Array.from(this.dataArray!.slice(0, 8)),
                    'å½“å‰é˜ˆå€¼': this.config.threshold.toFixed(3),
                    'è¶…è¿‡é˜ˆå€¼': ourAlgorithm >= this.config.threshold ? 'âœ…' : 'âŒ'
                });
            } else if (testCount % 10 === 0) {
                console.log(`ğŸ¤ é™éŸ³æ£€æµ‹ [${testCount + 1}/${maxTests}]: æ— éŸ³é¢‘è¾“å…¥`);
            }
            
            testCount++;
            if (testCount >= maxTests) {
                clearInterval(testInterval);
                console.log('ğŸ§ª é«˜ç²¾åº¦éŸ³é‡å“åº”æµ‹è¯•ç»“æŸ');
            }
        }, 1000);
    }

    private analyzeSpectrum(): any {
        if (!this.freqDataArray) {
            return {
                totalEnergy: 0,
                speechEnergy: 0,
                spectralCentroid: 0
            };
        }

        let totalEnergy = 0;
        let speechEnergy = 0;
        let weightedFreqSum = 0;
        let energySum = 0;

        const sampleRate = this.audioContext?.sampleRate || 48000;
        const nyquist = sampleRate / 2;
        const binSize = nyquist / this.freqDataArray.length;

        for (let i = 0; i < this.freqDataArray.length; i++) {
            const amplitude = this.freqDataArray[i] / 255;
            const energy = amplitude * amplitude;
            const frequency = i * binSize;

            totalEnergy += energy;

            // è¯­éŸ³é¢‘æ®µé€šå¸¸åœ¨ 85Hz - 4000Hz
            if (frequency >= 85 && frequency <= 4000) {
                speechEnergy += energy;
            }

            // è®¡ç®—é¢‘è°±é‡å¿ƒ
            weightedFreqSum += frequency * energy;
            energySum += energy;
        }

        const spectralCentroid = energySum > 0 ? weightedFreqSum / energySum : 0;

        return {
            totalEnergy,
            speechEnergy,
            spectralCentroid
        };
    }

    // æ–°å¢ï¼šè®¾ç½®è¯­éŸ³çŠ¶æ€å˜åŒ–å›è°ƒ
    setSpeechStateChangeCallback(callback: (isSpeaking: boolean) => void) {
        this.onSpeechStateChange = callback;
    }

    private updateSpeechState(probability: number) {
        const wasSpeeking = this.isSpeaking;
        
        // ä½¿ç”¨æ›´ä¸¥æ ¼çš„é˜ˆå€¼åˆ¤æ–­ï¼Œç¡®ä¿ä¸ç”µå¹³æ¡æ˜¾ç¤ºä¸€è‡´
        const isAboveThreshold = this.smoothedVolume >= this.config.threshold;
        
        if (isAboveThreshold) {
            this.speechFrameCount++;
            this.silenceFrameCount = 0;
            
            if (!this.isSpeaking && this.speechFrameCount >= this.config.minSpeechFrames) {
                this.isSpeaking = true;
                console.log(`ğŸ—£ï¸ æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹ (éŸ³é‡: ${this.smoothedVolume.toFixed(3)}, é˜ˆå€¼: ${this.config.threshold.toFixed(3)})`);
            }
        } else {
            this.silenceFrameCount++;
            this.speechFrameCount = 0;
            
            if (this.isSpeaking && this.silenceFrameCount >= this.config.minSilenceFrames) {
                this.isSpeaking = false;
                console.log(`ğŸ¤« æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ (éŸ³é‡: ${this.smoothedVolume.toFixed(3)}, é˜ˆå€¼: ${this.config.threshold.toFixed(3)})`);
            }
        }

        // æ–°å¢ï¼šå¦‚æœè¯­éŸ³çŠ¶æ€å‘ç”Ÿå˜åŒ–ï¼Œè§¦å‘å›è°ƒ
        if (wasSpeeking !== this.isSpeaking && this.onSpeechStateChange) {
            this.onSpeechStateChange(this.isSpeaking);
        }
    }

    private updateHistory(volume: number) {
        this.volumeHistory.push(volume);
        if (this.volumeHistory.length > this.historySize) {
            this.volumeHistory.shift();
        }
    }

    updateConfig(newConfig: Partial<VADConfig>) {
        this.config = { ...this.config, ...newConfig };
        console.log('âš™ï¸ VAD é…ç½®å·²æ›´æ–°:', this.config);
    }

    setVADCallback(callback: (result: VADResult) => void) {
        this.onVADUpdate = callback;
    }

    stopAnalysis() {
        this.isActive = false;
        console.log('â¹ï¸ VAD åˆ†æå·²åœæ­¢');
    }

    disconnect() {
        this.stopAnalysis();
        
        if (this.microphoneSource) {
            this.microphoneSource.disconnect();
            this.microphoneSource = null;
        }
        
        if (this.analyserNode) {
            this.analyserNode.disconnect();
            this.analyserNode = null;
        }
        
        this.dataArray = null;
        this.freqDataArray = null;
        this.onVADUpdate = null;
        
        console.log('ğŸ”Œ VAD å·²æ–­å¼€è¿æ¥');
    }

    dispose() {
        this.disconnect();
        
        if (this.audioContext && this.audioContext.state !== 'closed') {
            this.audioContext.close();
            this.audioContext = null;
        }
        
        console.log('ğŸ—‘ï¸ VAD å·²é”€æ¯');
    }

    // æ·»åŠ å¼ºåˆ¶æµ‹è¯•æ–¹æ³•
    testAudioInput(): void {
        console.log('ğŸ§ª å¼€å§‹VADéŸ³é¢‘è¾“å…¥æµ‹è¯•ï¼Œå½“å‰çŠ¶æ€æ£€æŸ¥...');
        console.log('ğŸ“Š VADåˆå§‹åŒ–çŠ¶æ€:', {
            hasAnalyser: !!this.analyserNode,
            hasDataArrays: !!(this.dataArray && this.freqDataArray),
            isActive: this.isActive,
            audioContextState: this.audioContext?.state
        });

        if (!this.analyserNode || !this.dataArray || !this.freqDataArray) {
            console.error('âŒ VADæœªæ­£ç¡®åˆå§‹åŒ–ï¼Œè¯¦ç»†çŠ¶æ€:', {
                analyserNode: !!this.analyserNode,
                dataArray: !!this.dataArray,
                freqDataArray: !!this.freqDataArray,
                audioContext: !!this.audioContext
            });
            return;
        }

        console.log('ğŸ§ª VADå·²æ­£ç¡®åˆå§‹åŒ–ï¼Œå¼€å§‹éŸ³é¢‘è¾“å…¥æµ‹è¯•...');
        
        const testInterval = setInterval(() => {
            if (!this.analyserNode || !this.dataArray || !this.freqDataArray) {
                console.error('âŒ æµ‹è¯•æœŸé—´VADè¢«é”€æ¯');
                clearInterval(testInterval);
                return;
            }

            this.analyserNode.getByteTimeDomainData(this.dataArray);
            this.analyserNode.getByteFrequencyData(this.freqDataArray);
            
            const volume = this.calculateVolume();
            const hasTimeData = this.dataArray.some(v => v !== 128);
            const hasFreqData = this.freqDataArray.some(v => v > 0);
            
            console.log('ğŸ§ª æµ‹è¯•ç»“æœ:', {
                volume: volume.toFixed(4),
                hasTimeData,
                hasFreqData,
                timeDataSample: Array.from(this.dataArray.slice(0, 5)),
                freqDataSample: Array.from(this.freqDataArray.slice(0, 5)),
                audioContextState: this.audioContext?.state
            });
            
            if (volume > 0.01) {
                console.log('âœ… æ£€æµ‹åˆ°éŸ³é¢‘è¾“å…¥ï¼');
                clearInterval(testInterval);
            }
        }, 500);
        
        // 10ç§’ååœæ­¢æµ‹è¯•
        setTimeout(() => {
            clearInterval(testInterval);
            console.log('ğŸ§ª VADéŸ³é¢‘æµ‹è¯•ç»“æŸ');
        }, 10000);
    }

    // è·å–å½“å‰çŠ¶æ€ç”¨äºè°ƒè¯•
    getDebugInfo() {
        return {
            isActive: this.isActive,
            config: this.config,
            currentVolume: this.currentVolume,
            smoothedVolume: this.smoothedVolume,
            isSpeaking: this.isSpeaking,
            speechFrameCount: this.speechFrameCount,
            silenceFrameCount: this.silenceFrameCount,
            volumeHistory: [...this.volumeHistory],
            audioContextState: this.audioContext?.state,
            analysisCount: this.analysisCount,
            hasAnalyser: !!this.analyserNode,
            hasDataArrays: !!(this.dataArray && this.freqDataArray),
            dataArrayLength: this.dataArray?.length || 0,
            lastAnalysisTime: this.lastAnalysisTime
        };
    }
}

export class VADAudioGateway {
    private audioContext: AudioContext | null = null;
    private sourceNode: MediaStreamAudioSourceNode | null = null;
    private gainNode: GainNode | null = null;
    private destinationNode: MediaStreamAudioDestinationNode | null = null;
    
    private isTransmitting = true;
    private targetGain = 1.0;
    private currentGain = 1.0;
    private fadeInterval: number | null = null;
    
    private onStateChange: ((result: any) => void) | null = null;
    private originalStream: MediaStream | null = null;

    constructor() {
        // ä¸åœ¨æ„é€ å‡½æ•°ä¸­åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡ï¼Œè€Œæ˜¯åœ¨è¿æ¥æ—¶åˆå§‹åŒ–
        console.log('ğŸ›ï¸ VADéŸ³é¢‘ç½‘å…³å·²åˆ›å»º');
    }

    private async initializeAudioContext() {
        try {
            // ç¡®ä¿åœ¨ç”¨æˆ·äº¤äº’ååˆ›å»ºéŸ³é¢‘ä¸Šä¸‹æ–‡
            this.audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
            
            // å¦‚æœéŸ³é¢‘ä¸Šä¸‹æ–‡å¤„äºæš‚åœçŠ¶æ€ï¼Œå°è¯•æ¢å¤
            if (this.audioContext.state === 'suspended') {
                await this.audioContext.resume();
                console.log('ğŸ›ï¸ éŸ³é¢‘ä¸Šä¸‹æ–‡å·²æ¢å¤');
            }
            
            // åˆ›å»ºå¢ç›ŠèŠ‚ç‚¹
            this.gainNode = this.audioContext.createGain();
            this.gainNode.gain.value = 1.0;
            
            // åˆ›å»ºç›®æ ‡æµèŠ‚ç‚¹
            this.destinationNode = this.audioContext.createMediaStreamDestination();
            
            // è¿æ¥éŸ³é¢‘å›¾
            this.gainNode.connect(this.destinationNode);
            
            console.log('ğŸ›ï¸ VADéŸ³é¢‘ç½‘å…³éŸ³é¢‘ä¸Šä¸‹æ–‡å·²åˆå§‹åŒ–');
            console.log('ğŸ” éŸ³é¢‘ä¸Šä¸‹æ–‡çŠ¶æ€:', this.audioContext.state);
            console.log('ğŸ” éŸ³é¢‘ä¸Šä¸‹æ–‡é‡‡æ ·ç‡:', this.audioContext.sampleRate);
            
        } catch (error) {
            console.error('âŒ VADéŸ³é¢‘ç½‘å…³åˆå§‹åŒ–å¤±è´¥:', error);
            throw error;
        }
    }

    async connectToStream(inputStream: MediaStream): Promise<MediaStream | null> {
        try {
            console.log('ğŸ”— VADéŸ³é¢‘ç½‘å…³å¼€å§‹è¿æ¥åˆ°è¾“å…¥æµ...');
            
            // éªŒè¯è¾“å…¥æµ
            const inputTracks = inputStream.getAudioTracks();
            if (inputTracks.length === 0) {
                throw new Error('è¾“å…¥æµæ²¡æœ‰éŸ³é¢‘è½¨é“');
            }
            
            const inputTrack = inputTracks[0];
            console.log('ğŸ” è¾“å…¥éŸ³é¢‘è½¨é“çŠ¶æ€:', {
                label: inputTrack.label,
                readyState: inputTrack.readyState,
                enabled: inputTrack.enabled,
                muted: inputTrack.muted,
                settings: inputTrack.getSettings()
            });
            
            if (inputTrack.readyState !== 'live') {
                throw new Error(`è¾“å…¥éŸ³é¢‘è½¨é“çŠ¶æ€æ— æ•ˆ: ${inputTrack.readyState}`);
            }
            
            // ä¿å­˜åŸå§‹æµå¼•ç”¨
            this.originalStream = inputStream;
            
            // åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡
            await this.initializeAudioContext();
            
            if (!this.audioContext || !this.gainNode || !this.destinationNode) {
                throw new Error('éŸ³é¢‘ç½‘å…³æœªæ­£ç¡®åˆå§‹åŒ–');
            }
            
            // åˆ›å»ºæºèŠ‚ç‚¹
            this.sourceNode = this.audioContext.createMediaStreamSource(inputStream);
            console.log('ğŸ”— å·²åˆ›å»ºéŸ³é¢‘æºèŠ‚ç‚¹');
            
            // è¿æ¥éŸ³é¢‘å›¾ï¼šæº -> å¢ç›Š -> ç›®æ ‡
            this.sourceNode.connect(this.gainNode);
            console.log('ğŸ”— éŸ³é¢‘å›¾å·²è¿æ¥');
            
            // éªŒè¯è¾“å‡ºæµ
            const outputStream = this.destinationNode.stream;
            const outputTracks = outputStream.getAudioTracks();
            
            if (outputTracks.length === 0) {
                throw new Error('è¾“å‡ºæµæ²¡æœ‰ç”ŸæˆéŸ³é¢‘è½¨é“');
            }
            
            const outputTrack = outputTracks[0];
            console.log('ğŸ” è¾“å‡ºéŸ³é¢‘è½¨é“çŠ¶æ€:', {
                label: outputTrack.label,
                readyState: outputTrack.readyState,
                enabled: outputTrack.enabled,
                muted: outputTrack.muted,
                settings: outputTrack.getSettings()
            });
            
            // ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿è½¨é“çŠ¶æ€ç¨³å®š
            await new Promise(resolve => setTimeout(resolve, 100));
            
            // å†æ¬¡æ£€æŸ¥è¾“å‡ºè½¨é“çŠ¶æ€
            if (outputTrack.readyState !== 'live') {
                throw new Error(`è¾“å‡ºéŸ³é¢‘è½¨é“çŠ¶æ€æ— æ•ˆ: ${outputTrack.readyState}`);
            }
            
            // ç›‘å¬è¾“å…¥è½¨é“çŠ¶æ€å˜åŒ–
            inputTrack.addEventListener('ended', () => {
                console.log('âš ï¸ è¾“å…¥éŸ³é¢‘è½¨é“å·²ç»“æŸï¼ŒVADéŸ³é¢‘ç½‘å…³å°†åœæ­¢');
                this.handleInputTrackEnded();
            });
            
            console.log('âœ… VADéŸ³é¢‘ç½‘å…³å·²æˆåŠŸè¿æ¥åˆ°è¾“å…¥æµ');
            return outputStream;
            
        } catch (error) {
            console.error('âŒ VADéŸ³é¢‘ç½‘å…³è¿æ¥å¤±è´¥:', error);
            this.cleanup();
            return null;
        }
    }

    private handleInputTrackEnded() {
        console.log('ğŸ›‘ å¤„ç†è¾“å…¥è½¨é“ç»“æŸäº‹ä»¶');
        // ä¸ç«‹å³æ¸…ç†ï¼Œè€Œæ˜¯é€šçŸ¥çŠ¶æ€å˜åŒ–
        if (this.onStateChange) {
            this.onStateChange({
                ...this.getState(),
                inputEnded: true
            });
        }
    }

    setTransmitting(transmitting: boolean, fadeTime: number = 50) {
        if (this.isTransmitting === transmitting) return;
        
        this.isTransmitting = transmitting;
        this.targetGain = transmitting ? 1.0 : 0.0;
        
        console.log(`ğŸ›ï¸ VADéŸ³é¢‘ç½‘å…³åˆ‡æ¢ä¼ è¾“çŠ¶æ€: ${transmitting ? 'å¼€å¯' : 'å…³é—­'}`);
        
        if (!this.gainNode || !this.audioContext) {
            console.warn('éŸ³é¢‘ç½‘å…³æœªåˆå§‹åŒ–ï¼Œæ— æ³•è®¾ç½®ä¼ è¾“çŠ¶æ€');
            return;
        }
        
        if (this.fadeInterval) {
            clearInterval(this.fadeInterval);
        }
        
        const steps = Math.max(1, fadeTime / 10);
        const fadeStep = Math.abs(this.targetGain - this.currentGain) / steps;
        
        this.fadeInterval = window.setInterval(() => {
            if (Math.abs(this.currentGain - this.targetGain) < fadeStep) {
                this.currentGain = this.targetGain;
                if (this.gainNode && this.audioContext && this.audioContext.state === 'running') {
                    this.gainNode.gain.value = this.currentGain;
                }
                
                if (this.fadeInterval) {
                    clearInterval(this.fadeInterval);
                    this.fadeInterval = null;
                }
                
                this.notifyStateChange();
            } else {
                if (this.currentGain < this.targetGain) {
                    this.currentGain = Math.min(this.targetGain, this.currentGain + fadeStep);
                } else {
                    this.currentGain = Math.max(this.targetGain, this.currentGain - fadeStep);
                }
                
                if (this.gainNode && this.audioContext && this.audioContext.state === 'running') {
                    this.gainNode.gain.value = this.currentGain;
                }
            }
        }, 10);
    }

    getState() {
        return {
            isControlling: true,
            isTransmitting: this.isTransmitting,
            outputVolume: this.currentGain,
            audioContextState: this.audioContext?.state || 'closed',
            hasValidOutput: this.destinationNode?.stream.getAudioTracks()[0]?.readyState === 'live'
        };
    }

    setStateChangeCallback(callback: (result: any) => void) {
        this.onStateChange = callback;
    }

    private notifyStateChange() {
        if (this.onStateChange) {
            this.onStateChange(this.getState());
        }
    }

    private cleanup() {
        if (this.fadeInterval) {
            clearInterval(this.fadeInterval);
            this.fadeInterval = null;
        }
        
        if (this.sourceNode) {
            try {
                this.sourceNode.disconnect();
            } catch (error) {
                console.warn('æ–­å¼€æºèŠ‚ç‚¹æ—¶å‡ºé”™:', error);
            }
            this.sourceNode = null;
        }
        
        if (this.gainNode) {
            try {
                this.gainNode.disconnect();
            } catch (error) {
                console.warn('æ–­å¼€å¢ç›ŠèŠ‚ç‚¹æ—¶å‡ºé”™:', error);
            }
            this.gainNode = null;
        }
    }

    disconnect() {
        console.log('ğŸ”Œ VADéŸ³é¢‘ç½‘å…³æ–­å¼€è¿æ¥');
        this.cleanup();
    }

    dispose() {
        console.log('ğŸ—‘ï¸ VADéŸ³é¢‘ç½‘å…³å¼€å§‹é”€æ¯');
        
        this.cleanup();
        
        // ä¸è¦å…³é—­éŸ³é¢‘ä¸Šä¸‹æ–‡ï¼Œè®©æµè§ˆå™¨ç®¡ç†
        if (this.audioContext) {
            console.log('ğŸ” ä¿ç•™éŸ³é¢‘ä¸Šä¸‹æ–‡ï¼Œè®©æµè§ˆå™¨ç®¡ç†');
            this.audioContext = null;
        }
        
        this.destinationNode = null;
        this.originalStream = null;
        this.onStateChange = null;
        
        console.log('âœ… VADéŸ³é¢‘ç½‘å…³å·²é”€æ¯');
    }
}